from Xcept2 import Xception
from data2 import ff_data , celeb_test , DFDC_test
from ca import CA_Block

import time
import torch
from torchvision import datasets, models, transforms
import os
import torch.nn as nn

from sklearn.ensemble import StackingClassifier

import copy
import torch.optim as optim
import torchvision
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader ,Dataset , random_split

import numpy as np
import joblib
from efficientnet_pytorch import EfficientNet
from PIL import Image
from torchsummary import summary
from sklearn.metrics import roc_auc_score
import torch.nn.functional as F

augmentation = torchvision.transforms.Compose([torchvision.transforms.Resize(160),
                                                    #torchvision.transforms.RandomCrop(200),                                                                            
                                                    #torchvision.transforms.RandomHorizontalFlip(),
                                                    torchvision.transforms.ToTensor(),
                                                    torchvision.transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])
                                                    ])

#torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])


def test(test_loader, model ):
    model.eval()
    y_s = []
    y_l = []
    val_accuracy = 0.0
    
    with torch.no_grad():
        for  inputs , labels in test_loader :
            
            inputs, labels = inputs.to(device , dtype=torch.float32), labels.to(device)
            outputs = model(inputs)
            
            m = nn.Softmax(dim=1)
            
            _, pred = torch.max(m(outputs), 1)
            
            y_s += (m(outputs)[:,1].cpu().data.numpy().tolist())
            y_l += (labels.cpu().data.numpy().tolist())
            
            val_accuracy += torch.sum(pred==labels).item()
# =============================================================================
#                 loss = criterion(outputs, labels)
#                 val_loss += loss.item()
# =============================================================================
    
        #print("val Loss: {}".format(val_loss / num ))    
        print("test Accuracy: {}".format(val_accuracy / len(a) ))
        print()
    
    f = open('./res.txt' , 'w')
    f.write("Test Accuracy: {}".format(val_accuracy / len(a) ))
    f.close()
    return np.array(y_l) , np.array(y_s)



class CA(nn.Module):
    def __init__(self, modelA, nb_classes=2):
        super(CA, self).__init__()
        self.modelA = modelA
        
        # Remove last linear layer
        self.modelA._fc = nn.Identity()
        
        self.ca_model = CA_Block(channel=2048, h=5, w=5)
        
        # Create new classifier
        self.classifier = nn.Linear(2048, nb_classes)
        
        
    def forward(self, x ):
        x = self.modelA.extract_features(x) 
        
        y = self.ca_model(x)
        x = torch.mul(y,x)
        
        x = self.modelA._avg_pooling(x)
        x = x.view(x.size(0), -1)
        x = self.modelA._dropout(x)
        
        x = self.classifier(x)
        x = self.modelA._swish(x)
        return x



if __name__ =="__main__":
     
     
    modelA = EfficientNet.from_pretrained('efficientnet-b5' , num_classes=2)
    model = CA( modelA )
                   
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    
    Batch_size = 8
         
    a = ff_data(transforms = augmentation , mode = 1 , batch = 100)  # mode0 : train , mode1 : test , mode2 : val
    #summary(model , (3,224,224)) 
    
    test_loader = DataLoader(a , batch_size = Batch_size )
    
    
   
    
    model.load_state_dict(torch.load('conter5.pth'))
    print(' ')
    print('now model is conter5')
    print(' ')
    a = ff_data(transforms = augmentation , mode = 1 , batch = 100)  # mode0 : train , mode1 : test , mode2 : val
    #summary(model , (3,224,224)) 
    
    test_loader = DataLoader(a , batch_size = Batch_size )
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))
    
    a = DFDC_test( r'D:\DFDC\frames' , transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))

    a = celeb_test( transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))



    model.load_state_dict(torch.load('conter10.pth'))
    print(' ')
    print('now model is conter10')
    print(' ')
    a = ff_data(transforms = augmentation , mode = 1 , batch = 100)  # mode0 : train , mode1 : test , mode2 : val
    #summary(model , (3,224,224)) 
    
    test_loader = DataLoader(a , batch_size = Batch_size )
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))
    
    a = DFDC_test( r'D:\DFDC\frames' , transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))

    a = celeb_test( transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))
    
    
    model.load_state_dict(torch.load('conter15.pth'))
    print(' ')
    print('now model is conter15')
    print(' ')
    a = ff_data(transforms = augmentation , mode = 1 , batch = 100)  # mode0 : train , mode1 : test , mode2 : val
    #summary(model , (3,224,224)) 
    
    test_loader = DataLoader(a , batch_size = Batch_size )
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))
    
    a = DFDC_test( r'D:\DFDC\frames' , transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))

    a = celeb_test( transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))
    
    
    model.load_state_dict(torch.load('conter30.pth'))
    print(' ')
    print('now model is conter30')
    print(' ')
    a = ff_data(transforms = augmentation , mode = 1 , batch = 100)  # mode0 : train , mode1 : test , mode2 : val
    #summary(model , (3,224,224)) 
    
    test_loader = DataLoader(a , batch_size = Batch_size )
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))
    
    a = DFDC_test( r'D:\DFDC\frames' , transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))

    a = celeb_test( transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))
    
    
    model.load_state_dict(torch.load('check_3.pth'))
    print(' ')
    print('now model is check_3')
    print(' ')
    a = ff_data(transforms = augmentation , mode = 1 , batch = 100)  # mode0 : train , mode1 : test , mode2 : val
    #summary(model , (3,224,224)) 
    
    test_loader = DataLoader(a , batch_size = Batch_size )
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))
    
    a = DFDC_test( r'D:\DFDC\frames' , transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))

    a = celeb_test( transforms = augmentation )
    test_loader = DataLoader(a , batch_size = Batch_size)
    
    y_label , y_score = test(test_loader , model )   
    print(roc_auc_score(y_label, y_score))


    
